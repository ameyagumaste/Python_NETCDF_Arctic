{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMYcsWDLZET0Vvf3SGZfKQo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ameyagumaste/Python_NETCDF_Arctic/blob/main/merge_CDF_Files_Apply_CF_Conventions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge Arctic NetCDF Files and Apply CF Conventions\n",
        "\n",
        "import xarray as xr\n",
        "import numpy as np\n",
        "import os\n",
        "from datetime import datetime as dt\n",
        "\n",
        "# 0. Create sample NetCDF files with simulated data to be merged\n",
        "output_folder = './arctic_data/'\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "latitude = [78.5, 79.0, 79.5]\n",
        "longitude = [30.0, 31.0]\n",
        "depth = [0, 10, 20]\n",
        "\n",
        "time = np.datetime64(\"2022-01-01\")\n",
        "time_range = [time + np.timedelta64(i, 'D') for i in range(3)]\n",
        "\n",
        "for i, t in enumerate(time_range):  # Create 3 sample files with time\n",
        "    salinity = np.random.uniform(30, 35, size=(3, 3, 2))\n",
        "    temperature = np.random.uniform(-2, 5, size=(3, 3, 2))\n",
        "    chlorophyll = np.random.uniform(0, 2, size=(3, 3, 2))\n",
        "\n",
        "    ds = xr.Dataset(\n",
        "        data_vars={\n",
        "            'salinity': (['depth', 'latitude', 'longitude'], salinity),\n",
        "            'temperature': (['depth', 'latitude', 'longitude'], temperature),\n",
        "            'chlorophyll_a': (['depth', 'latitude', 'longitude'], chlorophyll),\n",
        "        },\n",
        "        coords={\n",
        "            'depth': depth,\n",
        "            'latitude': latitude,\n",
        "            'longitude': longitude,\n",
        "            'time': t\n",
        "        }\n",
        "    )\n",
        "    ds = ds.expand_dims('time')\n",
        "    ds.to_netcdf(f\"{output_folder}/sample_data_{i+1}.nc\")\n",
        "\n",
        "# 1. Define folder and list of NetCDF files to merge\n",
        "nc_files = [f for f in os.listdir(output_folder) if f.endswith('.nc')]\n",
        "\n",
        "# 2. Load and merge NetCDF datasets\n",
        "merged_ds = xr.open_mfdataset([os.path.join(output_folder, f) for f in nc_files], combine='nested', concat_dim='time')\n",
        "\n",
        "# 3. Apply CF-convention compliant attributes\n",
        "merged_ds.attrs = {\n",
        "    'title': 'Merged Arctic Observational Dataset',\n",
        "    'summary': 'Combined NetCDF datasets for Arctic research with CF-compliant metadata.',\n",
        "    'creator_name': 'Ameya Gumaste',\n",
        "    'creator_email': 'ameyagumaste@gmail.com',\n",
        "    'institution': 'UVSQ - Universit√© Paris-Saclay',\n",
        "    'date_created': dt.utcnow().strftime(\"%Y-%m-%dT%H:%M:%SZ\"),\n",
        "    'Conventions': 'ACDD-1.3, CF-1.8',\n",
        "    'project': 'Arctic Climate Data Integration',\n",
        "    'license': 'https://creativecommons.org/licenses/by/4.0/'\n",
        "}\n",
        "\n",
        "# Add attributes for common Arctic coordinates\n",
        "if 'latitude' in merged_ds:\n",
        "    merged_ds['latitude'].attrs = {\n",
        "        'standard_name': 'latitude', 'long_name': 'Latitude', 'units': 'degrees_north', 'axis': 'Y'\n",
        "    }\n",
        "if 'longitude' in merged_ds:\n",
        "    merged_ds['longitude'].attrs = {\n",
        "        'standard_name': 'longitude', 'long_name': 'Longitude', 'units': 'degrees_east', 'axis': 'X'\n",
        "    }\n",
        "if 'depth' in merged_ds:\n",
        "    merged_ds['depth'].attrs = {\n",
        "        'standard_name': 'depth', 'long_name': 'Depth below sea surface', 'units': 'meters', 'positive': 'down', 'axis': 'Z'\n",
        "    }\n",
        "if 'time' in merged_ds:\n",
        "    merged_ds['time'].attrs = {\n",
        "        'standard_name': 'time', 'long_name': 'Time of observation'\n",
        "    }\n",
        "\n",
        "# Add variable-level CF attributes using a loop\n",
        "for var in merged_ds.data_vars:\n",
        "    if 'salinity' in var:\n",
        "        merged_ds[var].attrs.update({\n",
        "            'standard_name': 'sea_water_salinity',\n",
        "            'long_name': 'Sea Water Salinity',\n",
        "            'units': '1e-3',\n",
        "            'valid_min': 0.0,\n",
        "            'valid_max': 40.0,\n",
        "            'coverage_content_type': 'physicalMeasurement'\n",
        "        })\n",
        "    elif 'temperature' in var:\n",
        "        merged_ds[var].attrs.update({\n",
        "            'standard_name': 'sea_water_temperature',\n",
        "            'long_name': 'Sea Water Temperature',\n",
        "            'units': 'degree_Celsius',\n",
        "            'coverage_content_type': 'physicalMeasurement'\n",
        "        })\n",
        "    elif 'chlorophyll' in var:\n",
        "        merged_ds[var].attrs.update({\n",
        "            'standard_name': 'mass_concentration_of_chlorophyll_a_in_sea_water',\n",
        "            'long_name': 'Chlorophyll-a Concentration',\n",
        "            'units': 'ug m-3',\n",
        "            'coverage_content_type': 'physicalMeasurement'\n",
        "        })\n",
        "\n",
        "# 4. Export the merged and formatted dataset\n",
        "merged_ds.to_netcdf(\"merged_arctic_cf_dataset.nc\")\n",
        "print(\"Merged CF-compliant dataset saved as 'merged_arctic_cf_dataset.nc'\")\n",
        "\n",
        "# 5. Save a CSV demo from merged dataset\n",
        "csv_df = merged_ds['salinity'].isel(time=0).to_dataframe().reset_index()\n",
        "csv_df.to_csv(\"salinity_demo.csv\", index=False)\n",
        "print(\"Demo CSV saved as 'salinity_demo.csv'\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xUv7JQd4asqG",
        "outputId": "8abdf5df-5cc4-445d-f39a-453248212912"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Merged CF-compliant dataset saved as 'merged_arctic_cf_dataset.nc'\n",
            "Demo CSV saved as 'salinity_demo.csv'\n"
          ]
        }
      ]
    }
  ]
}